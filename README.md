I have analyzed  inference time of three DL models(Stable Diffusion, LLama2-7B,UniversalSentence Encoder ) on  5 difference serverless platforms(Baseten, Modal, HF Inference Endpoints, Runpod & Replicate). Results are in the jupyter notebooks.